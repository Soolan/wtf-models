"Original", "Optimized"
"Google is testing a product that uses artificial intelligence technology to produce news stories, pitching it to news organizations including The New York Times, The Washington Post and The Wall Street Journal’s owner, News Corp, according to three people familiar with the matter.The tool, known internally by the working title Genesis, can take in information — details of current events, for example — and generate news content, the people said, speaking on the condition of anonymity to discuss the product.One of the three people familiar with the product said that Google believed it could serve as a kind of personal assistant for journalists, automating some tasks to free up time for others, and that the company saw it as responsible technology that could help steer the publishing industry away from the pitfalls of generative A.I.Some executives who saw Google’s pitch described it as unsettling, asking not to be identified discussing a confidential matter. Two people said it seemed to take for granted the effort that went into producing accurate and artful news stories.Jenn Crider, a Google spokeswoman, said in a statement that in partnership with news publishers, especially smaller publishers, we’re in the earliest stages of exploring ideas to potentially provide A.I.-enabled tools to help their journalists with their work.Quite simply, these tools are not intended to, and cannot, replace the essential role journalists have in reporting, creating and fact-checking their articles, she added. Instead, they could provide options for headlines and other writing styles.A News Corp spokesman said in a statement, We have an excellent relationship with Google, and we appreciate Sundar Pichai’s long-term commitment to journalism.", "Google Explores AI-Driven News Content Production, Partnering with Leading Media Outlets Google is making strides in the realm of artificial intelligence, with its latest project aimed at revolutionizing news content production. The tech giant has been engaging in discussions with major news organizations, including The New York Times, The Washington Post, and News Corp, the owner of The Wall Street Journal, to introduce its groundbreaking AI-driven tool.Internally referred to as Genesis, this cutting-edge tool is designed to harness the power of artificial intelligence. It has the capacity to ingest vast amounts of data, including up-to-the-minute information on current events, and convert it into well-structured news articles. Sources familiar with the matter, who wished to remain anonymous, have confirmed these developments.The potential of Genesis extends beyond just generating news content; Google envisions it as a valuable assistant for journalists. By automating routine tasks, it aims to provide reporters with more time for creative and investigative work. Moreover, Google sees Genesis as a responsible technological advancement that could help the media industry avoid the challenges posed by generative AI.Despite Google's optimism, not everyone is onboard with the idea. Some executives who were privy to Google's proposal found it disconcerting. They expressed concerns, preferring to remain anonymous when discussing the confidential matter. It seemed to them that the proposal took for granted the rigorous effort required to produce accurate and captivating news stories.Responding to these developments, Jenn Crider, a Google spokeswoman, clarified the company's stance. She emphasized that Google intends to collaborate with news publishers, especially smaller ones, in the early stages of exploring AI-driven tools to support journalists in their work. Crider made it clear that these tools are not meant to replace the indispensable role that journalists play in reporting, crafting, and fact-checking articles. Instead, they are designed to offer options for headlines and various writing styles.A spokesman for News Corp expressed appreciation for Google's commitment to journalism. He highlighted the positive relationship between News Corp and Google, commending Sundar Pichai's long-term dedication to the field.In summary, Google's pursuit of AI-driven news content production, as seen with its Genesis project, signifies a potential transformation in the media industry. While the concept has garnered mixed reactions, Google's vision is to empower journalists and enhance the way news is created and delivered."
"ChatGPT, the AI-chatbot from OpenAI, which has an uncanny ability to answer any question, was likely your first introduction to AI. From writing poems, resumes and fusion recipes, the power of ChatGPT has been compared to autocomplete on steroids. But AI chatbots are only one part of the AI landscape. Sure, having ChatGPT help do your homework or having Midjourney create fascinating images of mechs based on country of origin is cool, but its potential could completely reshape economies. That potential could be worth $4.4 trillion to the global economy annually, according to McKinsey Global Institute, which is why you should expect to hear more and more about artificial intelligence. As people become more accustomed to a world intertwined with AI, new terms are popping up everywhere.So whether you're trying to sound smart over drinks or impress in a job interview, here are some important AI terms you should know. This glossary will continuously be updated. Artificial general intelligence, or AGI: A concept that suggests a more advanced versionof AI than we know today, one that can perform tasks much better than humans while also teaching and advancing its own capabilities.  AI ethics: Principles aimed at preventing AI from harming humans, achieved through means like determining how AI systems should collect data or deal with bias.  AI safety: An interdisciplinary field that's concerned with the long-term impacts of AI and how it could progress suddenly to a super intelligence that could be hostile to humans.  Algorithm: A series of instructions that allows a computer program to learn and analyze data in a particular way, such as recognizing patterns, to then learn from it and accomplish tasks on its own. Alignment: Tweaking an AI to better produce the desired outcome. This can refer to anything from moderating content to maintaining positive interactions toward humans.  Anthropomorphism: When humans tend to give nonhuman objects humanlike characteristics. In AI, this can include believing a chatbot is more humanlike and aware than it actually is, like believing it's happy, sad or even sentient altogether.  Artificial intelligence, or AI: The use of technology to simulate human intelligence, either in computer programs or robotics. A field in computer science that aims to build systems that can perform human tasks. Bias: In regards to large language models, errors resulting from the training data. This can result in falsely attributing certain characteristics to certain races or groups based on stereotypes. Chatbot: A program that communicates with humans through text that simulates human language.  ChatGPT: An AI chatbot developed by OpenAI that uses large language model technology. Cognitive computing: Another term for artificial intelligence. Data augmentation: Remixing existing data or adding a more diverse set of data to train an AI.  Deep learning: A method of AI, and a subfield of machine learning, that uses multiple parameters to recognize complex patterns in pictures, sound and text. The process is inspired by the human brain and uses artificial neural networks to create patterns. Diffusion: A method of machine learning that takes an existing piece of data, like a photo, and adds random noise. Diffusion models train their networks to re-engineer or recover that photo. Emergent behavior: When an AI model exhibits unintended abilities.  End-to-end learning, or E2E: A deep learning process in which a model is instructed to perform a task from start to finish. It's not trained to accomplish a task sequentially but instead learns from the inputs and solves it all at once.  Ethical considerations: An awareness of the ethical implications of AI and issues related to privacy, data usage, fairness, misuse and other safety issues.  Foom: Also known as fast takeoff or hard takeoff. The concept that if someone builds an AGI that it might already be too late to save humanity. Generative adversarial networks, or GANs: A generative AI model composed of two neural networks to generate new data: a generator and a discriminator. The generator creates new content, and the discriminator checks to see if it's authentic. Generative AI: A content-generating technology that uses AI to create text, video, computer code or images. The AI is fed large amounts of training data, finds patterns to generate its own novel responses, which can sometimes be similar to the source material. Google Bard: An AI chatbot by Google that functions similarly to ChatGPT but pulls information from the current web, whereas ChatGPT is limited to data until 2021 and isn't connected to the internet. Guardrails: Policies and restrictions placed on AI models to ensure data is handled responsibly and that the model doesn't create disturbing content.  Hallucination: An incorrect response from AI. Can include generative AI producing answers that are incorrect but stated with confidence as if correct. The reasons for this aren't entirely known. For example, when asking an AI chatbot, When did Leonardo da Vinci paint the Mona Lisa? it may respond with an incorrect statement saying, Leonardo da Vinci painted the Mona Lisa in 1815, which is 300 years after it was actually painted.  Large language model, or LLM: An AI model trained on mass amounts of text data to understand language and generate novel content in human-like language. Machine learning, or ML: A component in AI that allows computers to learn and make better predictive outcomes without explicit programming. Can be coupled with training sets to generate new content.  Microsoft Bing: A search engine by Microsoft that can now use the technology powering ChatGPT to give AI-powered search results. It's similar to Google Bard in being connected to the internet.  Multimodal AI: A type of AI that can process multiple types of inputs, including text, images, videos and speech.  Natural language processing: A branch of AI that uses machine learning and deep learning to give computers the ability to understand human language, often using learning algorithms, statistical models and linguistic rules. Neural network: A computational model that resembles the human brain's structure and is meant to recognize patterns in data. Consists of interconnected nodes, or neurons, that can recognize patterns and learn over time.  Overfitting: Error in machine learning where it functions too closely to the training data and may only be able to identify specific examples in said data but not new data.  Parameters: Numerical values that give LLMs structure and behavior, enabling it to make predictions. Prompt chaining: An ability of AI to use information from previous interactions to color future responses.  Stochastic parrot: An analogy of LLMs that illustrates that the software doesn't have a larger understanding of meaning behind language or the world around it, regardless of how convincing the output sounds. The phrase refers to how a parrot can mimic human words without understanding the meaning behind them.  Style transfer: The ability to adapt the style of one image to the content of another, allowing an AI to interpret the visual attributes of one image and use it on another. For example, taking the self-portrait of Rembrandt and re-creating it in the style of Picasso.  Temperature: Parameters set to control how random a language model's output is. A higher temperature means the model takes more risks. Text-to-image generation: Creating images based on textual descriptions. Training data: The datasets used to help AI models learn, including text, images, code or data. Transformer model: A neural network architecture and deep learning model that learns context by tracking relationships in data, like in sentences or parts of images. So, instead of analyzing a sentence one word at a time, it can look at the whole sentence and understand the context. Turing test: Named after famed mathematician and computer scientist Alan Turing, it tests a machine's ability to behave like a human. The machine passes if a human can't distinguish the machine's response from another human.  Weak AI, aka narrow AI: AI that's focused on a particular task and can't learn beyond its skill set. Most of today's AI is weak AI.  Zero-shot learning: A test in which a model must complete a task without being given the requisite training data. An example would be recognizing a lion while only being trained on tigers.","ChatGPT, the AI chatbot developed by OpenAI, is widely recognized for its remarkable ability to provide answers across a spectrum of questions. It likely served as your initial introduction to the world of artificial intelligence. From crafting poems, resumes, to fusion recipes, ChatGPT's capabilities have often been likened to an amped-up version of autocomplete.While AI chatbots like ChatGPT are just one facet of the expansive AI landscape, they have the potential to significantly influence various domains. While it's undoubtedly cool to have ChatGPT assist with your homework or watch Midjourney generate captivating mech illustrations based on their country of origin, the broader implications of AI are staggering. According to McKinsey Global Institute, AI's potential impact on the global economy could reach an astounding $4.4 trillion annually. This is why discussions about artificial intelligence are becoming increasingly prevalent.As society becomes increasingly intertwined with AI, there's a surge in the emergence of new AI-related terminology. Whether you're aiming to sound knowledgeable during casual conversations or hoping to impress in a job interview, here's a compilation of essential AI terms that should be on your radar.This AI glossary will remain dynamic, continually updated to reflect the evolving AI landscape.Artificial General Intelligence (AGI): AGI represents an advanced form of AI, exceeding the capabilities of current AI systems. AGI can perform tasks at a level far superior to humans while also being capable of teaching and enhancing its own abilities.AI Ethics: AI ethics involves the principles and guidelines aimed at preventing AI from causing harm to humans. This involves determining how AI systems should collect data and address biases, among other considerations.AI Safety: An interdisciplinary field focused on understanding the long-term implications of AI and its potential to rapidly evolve into a superintelligent entity that could pose risks to humanity.Algorithm: Algorithms are sets of instructions that enable computer programs to learn and analyze data in specific ways, such as pattern recognition, ultimately allowing them to perform tasks independently.Alignment: Alignment in AI refers to the process of fine-tuning an AI system to better align with desired outcomes. This can include moderating content or ensuring positive interactions with humans.Anthropomorphism: Anthropomorphism occurs when humans attribute human-like qualities to non-human entities. In the context of AI, it can involve perceiving a chatbot as more human-like or sentient than it actually is.Artificial Intelligence (AI): AI refers to the use of technology to simulate human intelligence, whether in the form of computer programs or robotics. It's a field within computer science dedicated to building systems capable of performing human-like tasks.Bias: In the context of large language models, bias refers to errors arising from the training data. This can lead to incorrect attributions of certain characteristics to particular races or groups based on stereotypes.Chatbot: A chatbot is a program that communicates with humans through text, simulating human language and conversation.ChatGPT: Developed by OpenAI, ChatGPT is an AI chatbot that leverages large language models to engage in natural language conversations.Cognitive Computing: Another term synonymous with artificial intelligence.Data Augmentation: Data augmentation involves remixing existing data or introducing a more diverse dataset to train AI models effectively.Deep Learning: A subfield of machine learning, deep learning employs multiple parameters to identify complex patterns in various data types, including images, sound, and text. It draws inspiration from the human brain and relies on artificial neural networks.Diffusion: Diffusion in machine learning involves introducing random noise to an existing dataset, such as an image. Diffusion models train networks to reconstruct or recover the original data.Emergent Behavior: Emergent behavior refers to instances where an AI model exhibits unexpected capabilities.End-to-End Learning (E2E): In E2E deep learning, models are trained to perform a task from start to finish without relying on sequential instructions, learning from inputs and solving tasks holistically.Ethical Considerations: Ethical considerations encompass awareness of the ethical implications of AI, encompassing issues related to privacy, data usage, fairness, misuse, and safety.Foom (Fast Takeoff or Hard Takeoff): Foom is a concept suggesting that if someone were to develop AGI, it might already be too late to prevent potential risks to humanity.Generative Adversarial Networks (GANs): GANs are generative AI models consisting of two neural networks: a generator and a discriminator. The generator produces new content, while the discriminator verifies its authenticity.Generative AI: Generative AI employs AI technology to create various forms of content, including text, video, computer code, or images. It uses extensive training data to identify patterns and generate novel responses.Google Bard: Google Bard is an AI chatbot by Google, similar to ChatGPT but with real-time internet connectivity. Unlike ChatGPT, it is not limited to data before 2021.Guardrails: Guardrails refer to policies and restrictions imposed on AI models to ensure responsible data handling and prevent the generation of disturbing content.Hallucination: In AI, hallucination refers to incorrect responses, where generative AI produces confidently stated but incorrect answers.Large Language Model (LLM): LLMs are AI models trained on extensive text data, enabling them to comprehend language and generate human-like content.Machine Learning (ML): ML is a component of AI that enables computers to learn and improve predictive outcomes without explicit programming. It can be paired with training data to generate new content.Microsoft Bing: Microsoft Bing is a search engine using technology similar to ChatGPT to provide AI-powered search results, similar to Google Bard, and is internet-connected.Multimodal AI: Multimodal AI can process various input types, including text, images, videos, and speech.Natural Language Processing (NLP): NLP is a branch of AI that leverages machine learning and deep learning to enable computers to understand human language, often using learning algorithms, statistical models, and linguistic rules.Neural Network: Neural networks are computational models inspired by the human brain's structure, designed to recognize patterns in data. They consist of interconnected nodes or neurons capable of pattern recognition and learning.Overfitting: Overfitting in machine learning occurs when a model closely matches training data but struggles to generalize to new data.Parameters: Parameters are numerical values that define the structure and behavior of LLMs, enabling them to make predictions.Prompt Chaining: Prompt chaining refers to an AI's ability to use information from previous interactions to influence future responses.Stochastic Parrot: Stochastic parrot is an analogy highlighting that LLMs lack a deep understanding of language or the world, despite producing convincing outputs.Style Transfer: Style transfer allows AI to adapt the style of one image to the content of another, enabling creative reinterpretations.Temperature: Temperature settings control the randomness of a language model's output. Higher temperatures result in more diverse responses.Text-to-Image Generation: Text-to-image generation involves creating images based on textual descriptions.Training Data: Training data comprises datasets used to facilitate AI model learning, including text, images, code, or other data types.Transformer Model: A neural network architecture and deep learning model that captures context by recognizing data relationships, allowing it to understand context across sentences or image components.Turing Test: Named after Alan Turing, the Turing test assesses a machine's ability to mimic human behavior. A machine passes the test if a human cannot distinguish its responses from those of another human.Weak AI (Narrow AI): Weak AI is AI specialized in specific tasks, incapable of learning beyond its designated functions, representing the majority of today's AI.Zero-Shot Learning: Zero-shot learning challenges a model to complete tasks without prior training data, such as recognizing a lion when trained only on tigers."
"A Hyderabad-based robotics firm has unveiled a state-of-the-art autonomous anti-drone system, powered by artificial intelligence. The system can protect not just vital installations like nuclear installations and oil rigs, but also a wide area encompassing even an entire city, from multiple drones of any kind. This is the first time such a system has been developed in India.This advanced full-spectrum drone security system capability was demonstrated live on the outskirts of Hyderabad by Grene Robotics, a deep-tech company that specialises in providing AI-powered security solutions for defence, enterprise, and government sectors.Named Indrajaal, it is said to be the world's only wide-area Counter-Unmanned Aircraft System (C-UAS). It can provide a comprehensive and integrated security mechanism against moving threats that cannot be tackled with static defence systems. Uttarakhand Governor Lieutenant General Gurmit Singh, who served as the Deputy Chief of Army Staff from 2014 to 2016, sees Indrajaal as a futuristic solution to India's security challenges in the defence, public infrastructure, and private sectors.We will never forget the June 27, 2021 drone attack on the Jammu airport and the June 15 Galwan attack. At that time, we wondered what solution we had against drones and swarms. Today, Indrajaal has given us the answer and shown that it is possible.Kiran Raju, the founder of Grene Robotics, which was established 12 years ago, says that Indrajaal's design uses a LEGO-like combination mechanism that offers 12 unique layers of technology powered by artificial intelligence.The system provides 360-degree protection, with the ability to detect, identify, classify, track, and neutralise threats in real time. The threat lifetime can be as short as 30 seconds to a few minutes, Mr Raju said.Indrajaal is designed to defend against all classes and levels of autonomous drones over an area of 4,000 square kilometres.","A Hyderabad-based robotics firm has unveiled a state-of-the-art autonomous anti-drone system, powered by artificial intelligence. The system can protect not just vital installations like nuclear installations and oil rigs, but also a wide area encompassing even an entire city, from multiple drones of any kind. This is the first time such a system has been developed in India. This advanced full-spectrum drone security system capability was demonstrated live on the outskirts of Hyderabad by Grene Robotics, a deep-tech company that specializes in providing AI-powered security solutions for defense, enterprise, and government sectors. Named Indrajaal, it is said to be the world's only wide-area Counter-Unmanned Aircraft System (C-UAS). It can provide a comprehensive and integrated security mechanism against moving threats that cannot be tackled with static defense systems. Uttarakhand Governor Lieutenant General Gurmit Singh, who served as the Deputy Chief of Army Staff from 2014 to 2016, sees Indrajaal as a futuristic solution to India's security challenges in the defense, public infrastructure, and private sectors. We will never forget the June 27, 2021 drone attack on the Jammu airport and the June 15 Galwan attack. At that time, we wondered what solution we had against drones and swarms. Today, Indrajaal has given us the answer and shown that it is possible. Kiran Raju, the founder of Grene Robotics, which was established 12 years ago, says that Indrajaal's design uses a LEGO-like combination mechanism that offers 12 unique layers of technology powered by artificial intelligence. The system provides 360-degree protection, with the ability to detect, identify, classify, track, and neutralize threats in real-time. The threat lifetime can be as short as 30 seconds to a few minutes, Mr. Raju said. Indrajaal is designed to defend against all classes and levels of autonomous drones over an area of 4,000 square kilometers."
"Students and office workers who carry heavy laptops and a plethora of personal items with them every day rely on backpacks to hold their belongings. For those people, there's good news: Microsoft may soon be infusing backpacks with artifical intelligence (AI) to take a backpack's function to a new level.A patent filed by Microsoft that showcases the concept of the AI backpack was filed on May 2, 2023, and published on August 24, 2023, as spotted by MSPowerUser. Also: One in four workers fears being considered 'lazy' if they use AI tools The wearable would be able to do much more than your average smartwatch, with advanced capabilities such as scanning an environment, understanding voice commands, and performing contextual tasks. ","Students and office workers who carry heavy laptops and a plethora of personal items with them every day rely on backpacks to hold their belongings. For those people, there's good news: Microsoft may soon be infusing backpacks with artificial intelligence (AI) to take a backpack's function to a new level. A patent filed by Microsoft that showcases the concept of the AI backpack was filed on May 2, 2023, and published on August 24, 2023, as spotted by MSPowerUser. Also: One in four workers fears being considered 'lazy' if they use AI tools. The wearable would be able to do much more than your average smartwatch, with advanced capabilities such as scanning an environment, understanding voice commands, and performing contextual tasks."
"There have been mutterings, including from within, that Google has fallen behind. A leaked memo from a Google engineer found its way on to the net, in which he said the firm had no AI secret sauce and was not in a position to win the race.This feeling was further fuelled by the battle of the bots.What is AI, is it dangerous and what jobs are at risk?'Google killer' ChatGPT sparks AI chatbot raceGoogle what our chatbot tell sdcx you... says Google For many people, the first time they knowingly interacted with AI - and were impressed by it - came in the form of ChatGPT, the viral AI chatbot which exploded into the world in November 2022.Its creator OpenAI has received billions of dollars in investment from Microsoft, which is now working it into its own products, including the Bing search engine and Office 365.ChatGPT has been dubbed the Google killer because of the way it can answer a question in one go, rather than serve up pages and pages of search results.It uses a language-processing architecture called a transformer which was actually invented by Google, but when Google followed up a few months later with its own rival Bard, it had nowhere near the same impact.Bard was given a surprisingly cautious launch. It was not for under-18s, the tech giant said, and it was described to me as an experiment by a senior exec.Perhaps part of its caution was in part a result of a weird situation which preceded Bard.","There have been mutterings, including from within, that Google has fallen behind. A leaked memo from a Google engineer found its way onto the net, in which he said the firm had no AI secret sauce and was not in a position to win the race. This feeling was further fueled by the battle of the bots.For many people, the first time they knowingly interacted with AI - and were impressed by it - came in the form of ChatGPT, the viral AI chatbot which exploded into the world in November 2022.Its creator OpenAI has received billions of dollars in investment from Microsoft, which is now working it into its own products, including the Bing search engine and Office 365.ChatGPT has been dubbed the Google killer because of the way it can answer a question in one go, rather than serve up pages and pages of search results. It uses a language-processing architecture called a transformer which was actually invented by Google, but when Google followed up a few months later with its own rival Bard, it had nowhere near the same impact. Bard was given a surprisingly cautious launch. It was not for under-18s, the tech giant said, and it was described to me as an experiment by a senior exec. Perhaps part of its caution was in part a result of a weird situation which preceded Bard."
"Compared to other imaging modalities like X-rays or CT scans, MRI scans provide high-quality soft tissue contrast. Unfortunately, MRI is highly sensitive to motion, with even the smallest of movements resulting in image artifacts. These artifacts put patients at risk of misdiagnoses or inappropriate treatment when critical details are obscured from the physician. But researchers at MIT may have developed a deep learning model capable of motion correction in brain MRI.Motion is a common problem in MRI,” explains Nalini Singh, an Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic)-affiliated PhD student in the Harvard-MIT Program in Health Sciences and Technology (HST) and lead author of the paper. It’s a pretty slow imaging modality.MRI sessions can take anywhere from a few minutes to an hour, depending on the type of images required. Even during the shortest scans, small movements can have dramatic effects on the resulting image. Unlike camera imaging, where motion typically manifests as a localized blur, motion in MRI often results in artifacts that can corrupt the whole image. Patients may be anesthetized or requested to limit deep breathing in order to minimize motion. However, these measures often cannot be taken in populations particularly susceptible to motion, including children and patients with psychiatric disorders. The paper, titled “Data Consistent Deep Rigid MRI Motion Correction, was recently awarded best oral presentation at the Medical Imaging with Deep Learning conference (MIDL) in Nashville, Tennessee. The method computationally constructs a motion-free image from motion-corrupted data without changing anything about the scanning procedure. Our aim was to combine physics-based modeling and deep learning to get the best of both worlds, Singh says.The importance of this combined approach lies within ensuring consistency between the image output and the actual measurements of what is being depicted, otherwise the model creates hallucinations — images that appear realistic, but are physically and spatially inaccurate, potentially worsening outcomes when it comes to diagnoses.","Compared to other imaging modalities like X-rays or CT scans, MRI scans provide high-quality soft tissue contrast. Unfortunately, MRI is highly sensitive to motion, with even the smallest of movements resulting in image artifacts. These artifacts put patients at risk of misdiagnoses or inappropriate treatment when critical details are obscured from the physician. But researchers at MIT may have developed a deep learning model capable of motion correction in brain MRI. Motion is a common problem in MRI, explains Nalini Singh, an Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic)-affiliated PhD student in the Harvard-MIT Program in Health Sciences and Technology (HST) and lead author of the paper. It’s a pretty slow imaging modality. MRI sessions can take anywhere from a few minutes to an hour, depending on the type of images required. Even during the shortest scans, small movements can have dramatic effects on the resulting image. Unlike camera imaging, where motion typically manifests as a localized blur, motion in MRI often results in artifacts that can corrupt the whole image. Patients may be anesthetized or requested to limit deep breathing in order to minimize motion. However, these measures often cannot be taken in populations particularly susceptible to motion, including children and patients with psychiatric disorders. The paper, titled Data Consistent Deep Rigid MRI Motion Correction, was recently awarded best oral presentation at the Medical Imaging with Deep Learning conference (MIDL) in Nashville, Tennessee. The method computationally constructs a motion-free image from motion-corrupted data without changing anything about the scanning procedure. Our aim was to combine physics-based modeling and deep learning to get the best of both worlds, Singh says. The importance of this combined approach lies within ensuring consistency between the image output and the actual measurements of what is being depicted, otherwise the model creates hallucinations — images that appear realistic, but are physically and spatially inaccurate, potentially worsening outcomes when it comes to diagnoses."
"As the impacts of climate change continue to grow, so does interest in fusion’s potential as a clean energy source. While fusion reactions have been studied in laboratories since the 1930s, there are still many critical questions scientists must answer to make fusion power a reality, and time is of the essence. As part of their strategy to accelerate fusion energy’s arrival and reach carbon neutrality by 2050, the U.S. Department of Energy (DoE) has announced new funding for a project led by researchers at MIT’s Plasma Science and Fusion Center (PSFC) and four collaborating institutions.Cristina Rea, a research scientist and group leader at the PSFC, will serve as the primary investigator for the newly funded three-year collaboration to pilot the integration of fusion data into a system that can be read by AI-powered tools. The PSFC, together with scientists from William & Mary, the University of Wisconsin at Madison, Auburn University, and the nonprofit HDF Group, plan to create a holistic fusion data platform, the elements of which could offer unprecedented access for researchers, especially underrepresented students. The project aims to encourage diverse participation in fusion and data science, both in academia and the workforce, through outreach programs led by the group’s co-investigators, of whom four out of five are women. The DoE’s award, part of a $29 million funding package for seven projects across 19 institutions, will support the group’s efforts to distribute data produced by fusion devices like the PSFC’s Alcator C-Mod, a donut-shaped “tokamak” that utilized powerful magnets to control and confine fusion reactions. Alcator C-Mod operated from 1991 to 2016 and its data are still being studied, thanks in part to the PSFC’s commitment to the free exchange of knowledge.","As the impacts of climate change continue to grow, so does interest in fusion’s potential as a clean energy source. While fusion reactions have been studied in laboratories since the 1930s, there are still many critical questions scientists must answer to make fusion power a reality, and time is of the essence.As part of their strategy to accelerate fusion energy’s arrival and reach carbon neutrality by 2050, the U.S. Department of Energy (DoE) has announced new funding for a project led by researchers at MIT’s Plasma Science and Fusion Center (PSFC) and four collaborating institutions.Cristina Rea, a research scientist and group leader at the PSFC, will serve as the primary investigator for the newly funded three-year collaboration to pilot the integration of fusion data into a system that can be read by AI-powered tools. The PSFC, together with scientists from William & Mary, the University of Wisconsin at Madison, Auburn University, and the nonprofit HDF Group, plan to create a holistic fusion data platform, the elements of which could offer unprecedented access for researchers, especially underrepresented students. The project aims to encourage diverse participation in fusion and data science, both in academia and the workforce, through outreach programs led by the group’s co-investigators, of whom four out of five are women.The DoE’s award, part of a $29 million funding package for seven projects across 19 institutions, will support the group’s efforts to distribute data produced by fusion devices like the PSFC’s Alcator C-Mod, a donut-shaped “tokamak” that utilized powerful magnets to control and confine fusion reactions. Alcator C-Mod operated from 1991 to 2016 and its data are still being studied, thanks in part to the PSFC’s commitment to the free exchange of knowledge."
"MIT Professor Jonathan How’s research interests span the gamut of autonomous vehicles — from airplanes and spacecraft to unpiloted aerial vehicles (UAVs, or drones) and cars. He is particularly focused on the design and implementation of distributed robust planning algorithms to coordinate multiple autonomous vehicles capable of navigating in dynamic environments.For the past year or so, the Richard Cockburn Maclaurin Professor of Aeronautics and Astronautics and a team of researchers from the Aerospace Controls Laboratory at MIT have been developing a trajectory planning system that allows a fleet of drones to operate in the same airspace without colliding with each other. Put another way, it is a multi-vehicle collision avoidance project, and it has real-world implications around cost savings and efficiency for a variety of industries including agriculture and defense.","MIT Professor Jonathan How’s research interests span the gamut of autonomous vehicles — from airplanes and spacecraft to unpiloted aerial vehicles (UAVs, or drones) and cars. He is particularly focused on the design and implementation of distributed robust planning algorithms to coordinate multiple autonomous vehicles capable of navigating in dynamic environments.For the past year or so, the Richard Cockburn Maclaurin Professor of Aeronautics and Astronautics and a team of researchers from the Aerospace Controls Laboratory at MIT have been developing a trajectory planning system that allows a fleet of drones to operate in the same airspace without colliding with each other. Put another way, it is a multi-vehicle collision avoidance project, and it has real-world implications around cost savings and efficiency for a variety of industries including agriculture and defense."
"Should artificial intelligence be allowed to make care decisions for patients? Though the future of AI may conjure up doomsday visions of robots and computers intent on rendering human existence superfluous, the MIT Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic) addressed questions surrounding the use of AI in health through their inaugural summer program focused on educating high school students. The Jameel Clinic Summer Program, which took place July 10-21, accepted a total of 51 students from primarily Boston-area schools, with a commitment to reaching students from diverse backgrounds.  The program, which split students up into two cohorts of 25 students for each week, had core offerings including courses like Intro to Python, Intro to Clinical AI, and Intro to Drug Discovery while also facilitating trips to various local institutions such as the Museum of Science Boston, Massachusetts General Hospital, Janssen Pharmaceuticals, and Amgen. Organizing this boot camp had a personal significance to me. When my family immigrated to Israel, it was tough — my parents and I worked minimum wage jobs to survive, School of Engineering Distinguished Professor and Jameel Clinic AI faculty lead Regina Barzilay recalls. Going to university transformed my life. Many of the students in the program have similar backgrounds. I hope that exposing them to exciting science at MIT will open new opportunities for them.","Should artificial intelligence be allowed to make care decisions for patients? Though the future of AI may conjure up doomsday visions of robots and computers intent on rendering human existence superfluous, the MIT Abdul Latif Jameel Clinic for Machine Learning in Health (Jameel Clinic) addressed questions surrounding the use of AI in health through their inaugural summer program focused on educating high school students.The Jameel Clinic Summer Program, which took place July 10-21, accepted a total of 51 students from primarily Boston-area schools, with a commitment to reaching students from diverse backgrounds.The program, which split students up into two cohorts of 25 students for each week, had core offerings including courses like Intro to Python, Intro to Clinical AI, and Intro to Drug Discovery while also facilitating trips to various local institutions such as the Museum of Science Boston, Massachusetts General Hospital, Janssen Pharmaceuticals, and Amgen.Organizing this boot camp had a personal significance to me. When my family immigrated to Israel, it was tough — my parents and I worked minimum wage jobs to survive, School of Engineering Distinguished Professor and Jameel Clinic AI faculty lead Regina Barzilay recalls. Going to university transformed my life. Many of the students in the program have similar backgrounds. I hope that exposing them to exciting science at MIT will open new opportunities for them."
"The MIT and Accenture Convergence Initiative for Industry and Technology has selected three new research projects that will receive support from the initiative. The research projects aim to accelerate progress in meeting complex societal needs through new business convergence insights in technology and innovation.Established in MIT’s School of Engineering and now in its third year, the MIT and Accenture Convergence Initiative is furthering its mission to bring together technological experts from across business and academia to share insights and learn from one another. Recently, Thomas W. Malone, the Patrick J. McGovern (1959) Professor of Management, joined the initiative as its first-ever faculty lead. The research projects relate to three of the initiative’s key focus areas: sustainability, digital health, and the future of work.The solutions these research teams are developing have the potential to have tremendous impact,” says Anantha Chandrakasan, dean of the School of Engineering and the Vannevar Bush Professor of Electrical Engineering and Computer Science. “They embody the initiative’s focus on advancing data-driven research that addresses technology and industry convergence.","The MIT and Accenture Convergence Initiative for Industry and Technology has selected three new research projects that will receive support from the initiative. The research projects aim to accelerate progress in meeting complex societal needs through new business convergence insights in technology and innovation.Established in MIT’s School of Engineering and now in its third year, the MIT and Accenture Convergence Initiative is furthering its mission to bring together technological experts from across business and academia to share insights and learn from one another. Recently, Thomas W. Malone, the Patrick J. McGovern (1959) Professor of Management, joined the initiative as its first-ever faculty lead. The research projects relate to three of the initiative’s key focus areas: sustainability, digital health, and the future of work.The solutions these research teams are developing have the potential to have tremendous impact, says Anantha Chandrakasan, dean of the School of Engineering and the Vannevar Bush Professor of Electrical Engineering and Computer Science. They embody the initiative’s focus on advancing data-driven research that addresses technology and industry convergence."
"Imagine you want to carry a large, heavy box up a flight of stairs. You might spread your fingers out and lift that box with both hands, then hold it on top of your forearms and balance it against your chest, using your whole body to manipulate the box. Humans are generally good at whole-body manipulation, but robots struggle with such tasks. To the robot, each spot where the box could touch any point on the carrier’s fingers, arms, and torso represents a contact event that it must reason about. With billions of potential contact events, planning for this task quickly becomes intractable.Now MIT researchers found a way to simplify this process, known as contact-rich manipulation planning. They use an AI technique called smoothing, which summarizes many contact events into a smaller number of decisions, to enable even a simple algorithm to quickly identify an effective manipulation plan for the robot.","Imagine you want to carry a large, heavy box up a flight of stairs. You might spread your fingers out and lift that box with both hands, then hold it on top of your forearms and balance it against your chest, using your whole body to manipulate the box.Humans are generally good at whole-body manipulation, but robots struggle with such tasks. To the robot, each spot where the box could touch any point on the carrier’s fingers, arms, and torso represents a contact event that it must reason about. With billions of potential contact events, planning for this task quickly becomes intractable.Now MIT researchers found a way to simplify this process, known as contact-rich manipulation planning. They use an AI technique called smoothing, which summarizes many contact events into a smaller number of decisions, to enable even a simple algorithm to quickly identify an effective manipulation plan for the robot."
"The Singapore MIT-Alliance for Research and Technology (SMART), MIT’s research enterprise in Singapore, has launched a new interdisciplinary research group aimed at tackling key social and institutional challenges around the rise of artificial intelligence and other new technologies. The group, known as Mens, Manus and Machina: How AI Empowers People, Institutions and the City in Singapore (M3S), aims to advance knowledge in these fields and foster collaborative research that generates positive impact for society in Singapore and the world.Seeking to redefine the boundaries of AI, automation, and robotics through interdisciplinary research, knowledge sharing, and impactful collaborations, SMART M3S endeavors to design inclusive, resilient, and innovative solutions that empower individuals, institutions, and cities. By exploring the intricate relationship between human capabilities, emerging technologies, and societal structures, it is envisioned that SMART M3S will drive scientific, societal, and commercial impact in Singapore and beyond.In line with Singapore’s Smart Nation initiative and its National AI Strategy, the project will embark on an ambitious five-year endeavor supported by a multimillion-dollar grant from the National Research Foundation of Singapore under its Campus for Research Excellence And Technological Enterprise program.","The Singapore MIT-Alliance for Research and Technology (SMART), MIT’s research enterprise in Singapore, has launched a new interdisciplinary research group aimed at tackling key social and institutional challenges around the rise of artificial intelligence and other new technologies. The group, known as Mens, Manus and Machina: How AI Empowers People, Institutions and the City in Singapore (M3S), aims to advance knowledge in these fields and foster collaborative research that generates positive impact for society in Singapore and the world.Seeking to redefine the boundaries of AI, automation, and robotics through interdisciplinary research, knowledge sharing, and impactful collaborations, SMART M3S endeavors to design inclusive, resilient, and innovative solutions that empower individuals, institutions, and cities. By exploring the intricate relationship between human capabilities, emerging technologies, and societal structures, it is envisioned that SMART M3S will drive scientific, societal, and commercial impact in Singapore and beyond.In line with Singapore’s Smart Nation initiative and its National AI Strategy, the project will embark on an ambitious five-year endeavor supported by a multimillion-dollar grant from the National Research Foundation of Singapore under its Campus for Research Excellence And Technological Enterprise program."
"ChatGPT has made headlines around the world with its ability to write essays, email, and computer code based on a few prompts from a user. Now an MIT-led team reports a system that could lead to machine-learning programs several orders of magnitude more powerful than the one behind ChatGPT. The system they developed could also use several orders of magnitude less energy than the state-of-the-art supercomputers behind the machine-learning models of today.In the July 17 issue of Nature Photonics, the researchers report the first experimental demonstration of the new system, which performs its computations based on the movement of light, rather than electrons, using hundreds of micron-scale lasers. With the new system, the team reports a greater than 100-fold improvement in energy efficiency and a 25-fold improvement in compute density, a measure of the power of a system, over state-of-the-art digital computers for machine learning. ","ChatGPT has made headlines around the world with its ability to write essays, email, and computer code based on a few prompts from a user. Now an MIT-led team reports a system that could lead to machine-learning programs several orders of magnitude more powerful than the one behind ChatGPT. The system they developed could also use several orders of magnitude less energy than the state-of-the-art supercomputers behind the machine-learning models of today.In the July 17 issue of Nature Photonics, the researchers report the first experimental demonstration of the new system, which performs its computations based on the movement of light, rather than electrons, using hundreds of micron-scale lasers. With the new system, the team reports a greater than 100-fold improvement in energy efficiency and a 25-fold improvement in compute density, a measure of the power of a system, over state-of-the-art digital computers for machine learning."
"The MIT Stephen A. Schwarzman College of Computing has awarded seed grants to seven projects that are exploring how artificial intelligence and human-computer interaction can be leveraged to enhance modern work spaces to achieve better management and higher productivity.Funded by Andrew W. Houston ’05 and Dropbox Inc., the projects are intended to be interdisciplinary and bring together researchers from computing, social sciences, and management.The seed grants can enable the project teams to conduct research that leads to bigger endeavors in this rapidly evolving area, as well as build community around questions related to AI-augmented management.","The MIT Stephen A. Schwarzman College of Computing has awarded seed grants to seven projects that are exploring how artificial intelligence and human-computer interaction can be leveraged to enhance modern work spaces to achieve better management and higher productivity. Funded by Andrew W. Houston ’05 and Dropbox Inc., the projects are intended to be interdisciplinary and bring together researchers from computing, social sciences, and management. The seed grants can enable the project teams to conduct research that leads to bigger endeavors in this rapidly evolving area, as well as build community around questions related to AI-augmented management."
